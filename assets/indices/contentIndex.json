{
  "/": {
    "title": "Weaver",
    "content": "",
    "lastmodified": "2022-12-12T16:34:59.694166227+01:00",
    "tags": null
  },
  "/Anton-Robert": {
    "title": "Anton Robert",
    "content": "\t\nHello!\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/images/profil.png\" height=300px /\u003e\u003c/p\u003e\n\nI'm a **physical chemist**, currently carrying a PhD thesis in **epistemology of biology**.   \nYou can take a look at my [PhD project](PhD%20project.md).     \nHere is a way to get in touch: \u003ca href=\"mailto:anton.smirnov.robert@gmail.com\"\u003e anton(dot)smirnov(dot)robert(at)gmail(dot)com \u003c/a\u003e.\n\nIf you are interested in the website **Weaver**, follow the link: [Where am I?](Where%20am%20I?.md)\n\nHere are the main points of my \u003ca href=\"/images/CV_07_23_internet_version.pdf\" \u003eCV\u003c/a\u003e[^1] : \n-  **PhD degree** in **physical chemistry** from Paris Sciences et Lettres Research University (2022).  \n- **Diploma** from the **√âcole Normale Sup√©rieure** **(ENS)** of Paris (2019).\n- **Master's degree** in analytical, physical and theoretical chemistry from **Sorbonne Universit√©** (2019).\n- Contracted visitor in **IBM Research Z√ºrich** on quantum computing for chemistry (2018-2019)\n\n\n### List of research publications (üìÑ) and patents (üí°)\n\n\nüìÑ Robert, Anton. 2023. ¬´ L‚ÄôarreÃÇt de l‚Äôhistoire des sciences ¬ª. Philosophy World Democracy.\n\nüìÑ Robert, Anton, H√©l√®ne Berthoumieux, et Marie-Laure Bocquet. 2023. ¬´¬†Coupled Interactions at the Ionic Graphene-Water Interface¬†¬ª. _Physical Review Letters_ 130 (7): 076201.\n\nüìÑ Robert, Anton, Panagiotis Kl Barkoutsos, Stefan Woerner, et Ivano Tavernelli. 2021. ¬´¬†Resource-efficient quantum algorithm for protein folding¬†¬ª. _npj Quantum Information_ 7 (1): 1‚Äë5.\n\nüìÑ Cuxart, Marc G., Knud Seufert, Valeria Chesnyak, Wajahat A. Waqas, Anton Robert, Marie-Laure Bocquet, Georg S. Duesberg, Hermann Sachdev, et Willi Auw√§rter. 2021. ¬´¬†Borophenes made easy¬†¬ª. _Science advances_ 7 (45): eabk1490.\n\nüí°Robert, Anton, Panagiotis Barkoutsos, Stefan Woerner, et Ivano Tavernelli. 2021. Branched heteropolymer lattice model for quantum optimization. United States US20210035003A1, filed 30 juillet 2019, et issued 4 f√©vrier 2021.\n\nüìÑ Baklanov, Aleksandr, Manuela Garnica, Anton Robert, Marie-Laure Bocquet, Knud Seufert, Johannes T. K√ºchle, Paul TP Ryan, Felix Haag, Reza Kakavandi, et Francesco Allegretti. 2020. ¬´¬†On-surface synthesis of nonmetal porphyrins¬†¬ª. _Journal of the American Chemical Society_ 142 (4): 1871‚Äë81.\n\nüìÑ Robert, Anton, Sohvi Luukkonen, et Maximilien Levesque. 2020. ¬´¬†Pressure correction for solvation theories¬†¬ª. _The Journal of Chemical Physics_ 152 (19): 191103.\n\nüìÑ Barkoutsos, Panagiotis Kl, Giacomo Nannicini, Anton Robert, Ivano Tavernelli, et Stefan Woerner. 2020. ¬´¬†Improving variational quantum optimization using CVaR¬†¬ª. _Quantum_ 4: 256.\n\nüí°Robert, Anton, Panagiotis Barkoutsos, Giacomo Nannicini, Ivano Tavernelli, et Stefan Woerner. 2020. Enhancing hybrid quantum-classical algorithms for optimization. United States US10671696B2, filed 4 octobre 2018, et issued 2 juin 2020.\n\nüìÑ Grosjean, Beno√Æt, Anton Robert, Rodolphe Vuilleumier, et Marie-Laure Bocquet. 2020. ¬´¬†Spontaneous liquid water dissociation on hybridised boron nitride and graphene atomic layers from ab initio molecular dynamics simulations¬†¬ª. _Physical Chemistry Chemical Physics_ 22 (19): 10710‚Äë16.\n\n\n[^1]: Reload a second time on the page if there is the \"null\" bug.  ",
    "lastmodified": "2023-07-01T13:41:15.676131603+02:00",
    "tags": null
  },
  "/PhD-project": {
    "title": "PhD project",
    "content": "\n\n![](images/projet_de_recherche_540.pdf)\n\n",
    "lastmodified": "2023-06-30T12:31:40.834824373+02:00",
    "tags": null
  },
  "/Where-am-I": {
    "title": "Where am I?",
    "content": "\nWelcome!\n\nYou are on my personal website. You can find out [about me](Anton%20Robert.md) by clicking on the red bold link.\n\nI created **Weaver** (*tisserand*/*tisserin* in French) to organize and access my literature notes using the [Zettelkasten](https://en.wikipedia.org/wiki/Zettelkasten) method. \nIt takes the form of a local [Wikipedia](https://en.wikipedia.org/wiki/Main_Page) with a nice graphical interface. \nIt forces *me* to make (**relatively**) clear sentences and proper notes.\nWeaver continuously needs work to be maintained, but it is not a goal in itself.\nIt is like a daily exercise, for leaving the nest with some understanding of articles.\n\nWeaver constitutes an example of an original academic workflow that can be made with numerical technologies. \nFor an **example**, see the [note on Longo2012](note/note%20on%20Longo2012.md). The rest of the website is private, and is worthless to you: make your own one!\n\nThis is how I organize myself. I split the entries in **four tags**:\n- **definitions**: words that I did not know or common words whose meaning is worth specifying in a given context. \n- **concepts**\n- **references** they are automatically generated pages with reference to a document and the commented quotes I highlighted in the PDF document. \n- **notes**: they are most often literature notes, augmented summaries of documents, organized in terms of atomized and linked definitions, concepts, and references. \n\nAt the end of each page, I can access the local graph (with depth 2) around my location.\nTo get the big picture, I can also zoom or drag nodes on the global graph that contains all entries (click on **Weaver** in the top-left corner of the page). \n\nHere are more technical aspects aspects [[about the website]] or my workflow. \n\n![](images/weaver.png)\n\u003cp style=\"text-align: center;\"\u003e \u003csub\u003e Image: Village weaver (Ploceus cucullatus). Credits: K.B. Newman‚ÄîNHPA/Encyclop√¶dia Britannica, Inc. \u003c/sub\u003e\u003c/p\u003e\n\n",
    "lastmodified": "2023-06-30T12:36:19.347511406+02:00",
    "tags": null
  },
  "/about-the-website": {
    "title": "about the website",
    "content": "\n\nTo build this website I use several open-source software/plugins. Each one represent a step of my workflow:\n- [Zotero](https://www.zotero.org/) and [Better BibTex](https://retorque.re/zotero-better-bibtex/) to reference, annotate documents locally.\n- [BibNotes Formatter](https://github.com/stefanopagliari/bibnotes) to import references and PDF quotes/notes in [Obsidian](https://obsidian.md/).\n- [Quartz](https://github.com/jackyzha0/quartz) to publish my Obsidian vault and [Hugo](https://gohugo.io/templates/) for design refinements. \n- Everything is synchronized on [Github](https://github.com/) that also hosts the webpage. \n\nI'm very thankful to all the developpers whose work allow this website to exist, especially to [jackyzha0](https://github.com/jackyzha0). \n",
    "lastmodified": "2022-12-11T18:09:54.676017181+01:00",
    "tags": null
  },
  "/concept/Brillouins-relation-between-entropy-and-information": {
    "title": "Brillouin's relation between entropy and information",
    "content": "\nIn 1951, Brilliouin related information and entropy to resolve [Maxwell's demon paradox](concept/Maxwell's%20demon%20paradox.md); more precisely [Shannon's theory of information transmission](concept/Shannon's%20theory%20of%20information%20transmission.md) and the [second principle of thermodynamics](concept/second%20principle%20of%20thermodynamics.md). He used the word  [negentropy](definition/negentropy.md) (first used in [Schrodinger1944](reference/Schrodinger1944.md)). Here, it reads **high entropy = low information**. \n\n#### Sources\n\n[Brillouin1951](reference/Brillouin1951.md)     \n[Brillouin1956](reference/Brillouin1956.md)\n",
    "lastmodified": "2023-07-01T12:59:58.079219846+02:00",
    "tags": null
  },
  "/concept/Chaitins-algorithmic-randomness": {
    "title": "Chaitin's algorithmic randomness",
    "content": "\nChaitin suggested that [Kolmogorov's incompressibility](concept/Kolmogorov's%20incompressibility.md) could be considered to be a definition of randomness.\n\nTo give an example of a random sequence, he exhibited an uncomputable (see [computability](concept/computability.md)) number (Chaintin's Omega) which is  the probability that a Turing machine halts (see the [halting problem](concept/halting%20problem.md)) reading a randomly generated program (toss a coin to obtain binaries).\n",
    "lastmodified": "2023-07-01T13:00:53.886255506+02:00",
    "tags": null
  },
  "/concept/Cricks-central-dogma": {
    "title": "Crick's central dogma",
    "content": "\nIt postulates that proteins never transmit \"sequential information\".\n\"Sequential information\" is to be understood as the sequence of bases in DNA or amino-acids in proteins. \n\n#### Sources\n\n[Crick1958](reference/Crick1958.md)\n[Crick1970](reference/Crick1970.md)\n[Wikipedia](https://en.wikipedia.org/wiki/Central_dogma_of_molecular_biology#:~:text=The%20central%20dogma%20of%20molecular,The%20Central%20Dogma.)\n",
    "lastmodified": "2023-07-01T12:58:16.881886112+02:00",
    "tags": null
  },
  "/concept/Kolmogorovs-incompressibility": {
    "title": "Kolmogorov's incompressibility",
    "content": "\nFor [Turing machine](concept/Turing%20machine.md)s, a sequence of 0's and 1's is incompressible if it cannot be generated by a program shorter than the sequence itself. \n",
    "lastmodified": "2023-07-01T13:00:42.098945013+02:00",
    "tags": null
  },
  "/concept/Laplacian-determinism": {
    "title": "Laplacian determinism",
    "content": "\nA demiurge could predict the future with solely the position and velocity of all particles in the universe. \nLaplace states that any [deterministic system](definition/deterministic%20system.md) is therefore predictable. \nIt is false because of [Poincare's unpredictable determinism](concept/Poincare's%20unpredictable%20determinism.md).  \n\n#### Sources\n\n[note on Longo2012](note/note%20on%20Longo2012.md)\n",
    "lastmodified": "2023-07-01T12:59:35.80334619+02:00",
    "tags": null
  },
  "/concept/Mendelian-inheritance": {
    "title": "Mendelian inheritance",
    "content": "\nIn 1865, the monk and botanist Gregor Mendel find that a trait can have different variants (alleles).\n\nHe did not used the word \"gene\", this *basic unit of heredity* was called as such decades later. Molecular genes as sequences of nucleotides in DNA came a hundred years later. \n\nMendel suggested three laws:\n\n- Some alleles are dominant while others are recessive.\n- Each gamete carries only one allele for each gene.\n- Genes of different traits can segregate independently during the formation of gametes (meiose).\n\n#### Sources \n\n[Wikipedia](https://en.wikipedia.org/wiki/Mendelian_inheritance)\n\n",
    "lastmodified": "2023-07-01T12:58:29.097264257+02:00",
    "tags": null
  },
  "/concept/Schrodingers-code-script-aperiodic-crystal": {
    "title": "Schr√∂dinger's code-script aperiodic crystal",
    "content": "\nIn 1944, Schr√∂dinger imagine that a ‚Äúcode-script‚Äù could be found in ‚Äúaperiodic crystals‚Äù (chromosomes) of living systems ([Schrodinger1944](reference/Schrodinger1944.md)). \n\n\n\u003e[!quote]\n\u003eOrganic chemistry, indeed, in investigating more and more complicated molecules, has come very much nearer to that 'aperiodic crystal' which, in my opinion, is the material carrier of life. ‚Äî (p.5)\n\u003e\n\n\nWithout mentionning ‚Äúinformation‚Äù, it does refer to a discrete encoding and therefore implies Laplacian determinism (and predictability). This was also acknowledge by the author. \n\n\n\u003e[!quote]\n\u003e\n\u003eIn calling the structure of the chromosome fibers a code-script we mean that the all-penetrating mind, once conceived by Laplace, (...) could tell from their structure whether the egg would develop, under suitable conditions, into a black cock or into a speckled hen ‚Äî (p. 21)\n\n\n",
    "lastmodified": "2023-07-01T12:57:46.474569419+02:00",
    "tags": null
  },
  "/concept/Shannons-theory-of-information-transmission": {
    "title": "Shannon's theory of information transmission",
    "content": "Be $X$  a random variable with $X\\in\\{x_1,x_2,...,x_n\\}$ and $p_i=\\mathbb{P}(X=x_i)$. Shannon relates the amount of information of one string to the amount of surprise of seeing it. The information is defined as $$I(X) = - \\log(P(X))$$and the expected value gives the amount of  \"**information, choice or uncertainty**\" ‚Äî [Shannon1948](reference/Shannon1948.md) as follows  $$H(X)=E(I(X))=-\\sum_i p_i \\log(p_i)$$This formula happens to be the same as the one for Gibbs [entropy](definition/entropy.md) (with an additional Boltzmann constant) in the framework of the [second principle of thermodynamics](concept/second%20principle%20of%20thermodynamics.md). Therefore, Shannon makes the link between information and positive entropy (see [Brillouin's relation between entropy and information](concept/Brillouin's%20relation%20between%20entropy%20and%20information.md)). This is peculiar because as entropy (and disorder) increases, information is lost. It is now preferred to give the name **entropy** to $H(X)$.  We use the meaning of **uncertainty** in this case. \n\n#### Exemple(s)\nA series of fair coin tosses have a maximal entropy $H$ since all throw are equiprobable (maximal uncertainty). \n\n#### Sources \n[Shannon1948](reference/Shannon1948.md)\n",
    "lastmodified": "2023-07-01T13:02:20.353420548+02:00",
    "tags": null
  },
  "/concept/Turing-machine": {
    "title": "Turing machine",
    "content": "In 1936, Turing introduces the idea of a ‚Äúcomputing machine‚Äù, latter called ‚ÄúTuring machine‚Äù. He pictures not a mecanism but a person ‚Äî ‚ÄúTuring's architect‚Äù according to ([Schrodinger1944](reference/Schrodinger1944.md)) Turing introduced ([Turing1936](reference/Turing1936.md)) this machine trying to answer questions regarding decidability. A Turing machine is an [automaton](definition/automaton.md) with an unlimited and unrestricted memory. It is a model of everything that can do today's computers. It requires a (readable, writtable, and movable) infinite 1D bit register ‚Äî a tape. Turing has shown that those elementary instructions are enough to do elaborate any sophisticated program that are themselves encoded on the tape. The Turing machine allocates a data space to make the computation and another one where the programs are encoded. The operating system read the instructions as it computes the program and change the input binary string. Increasing the complexity of the machine (e.g. alphabet, dimensions) does not change the class of functions it can computes ([recursive function](definition/recursive%20function.md)s). \n\n\n#### Details \n\n**What is the formal definition of a Turing machine ?** \nThe alphabet of the tape $\\Gamma$ can be thought to be 0's and 1's and blank's. \n\n$$\\begin{array}{l}\\text { A Turing machine is a 7-tuple, }\\left(Q, \\Sigma, \\Gamma, \\delta, q_{0}, q_{\\text {accept }}, q_{\\text {reject }}\\right) \\text {, where } \\\\ Q, \\Sigma, \\Gamma \\text { are all finite sets and } \\\\ \\text { 1. } Q \\text { is the set of states, } \\\\ \\text { 2. } \\Sigma \\text { is the input alphabet not containing the blank symbol } \\sqcup \\text {, } \\\\ \\text { 3. } \\Gamma \\text { is the tape alphabet, where } \\sqcup \\in \\Gamma \\text { and } \\Sigma \\subseteq \\Gamma \\text {, } \\\\ \\text { 4. } \\delta: Q \\times \\Gamma \\longrightarrow Q \\times \\Gamma \\times\\{\\mathrm{L}, \\mathrm{R}\\} \\text { is the transition function, } \\\\ \\text { 5. } q_{0} \\in Q \\text { is the start state, } \\\\ \\text { 6. } q_{\\text {accept }} \\in Q \\text { is the accept state, and } \\\\ \\text { 7. } q_{\\text {reject }} \\in Q \\text { is the reject state, where } q_{\\text {reject }} \\neq q_{\\text {accept }}\\end{array}$$\n\n**How to write the program (or diagram or table of instructions) in the machine ?**\n\nWe write $S_0=blank$ , $S_1=0$ and $S_2=1$, $R=move \\ right$, $L= move \\ left$ . \nAn instruction can be written $q_i S_i S_j R q_m$  or  $q_i S_i S_j L q_m$. We encode all instructions that define the Turing machine, as follows $$q_1 S_0 S_0 L q_2 ; q_2 S_1 S_2 L q_3 ; ... $$We write $q_i=DAAAA...A$ ($i$  times), $S_i=DCCC...C$ ($i$  times) and give a integer to each letter (A=1, C=2, D=3,...,;=7). Therefore, it gives a description number for the Turing machine $$313325117 ...$$There is a unique integer for a given machine, but we can always add unecessary programs (that change the number but that give the same result). This integer gets a binary decomposition$$01000101011010$$With the help of an additional small and instantaneous \"workspace\", it uses a [simple mecanism](https://www.youtube.com/watch?v=P66h8D5Lkwk) to read the programs and compute at the same time.\n\n\n#### Sources \n[Stanford Encyclopedia of Philosophy](https://plato.stanford.edu/entries/turing-machine/#TuriDefi)   \n[MIT Open courses](https://ocw.mit.edu/courses/18-404j-theory-of-computation-fall-2020/pages/syllabus/)     \n[Sipser2013](reference/Sipser2013.md)\nnote [note on Longo2012](note/note%20on%20Longo2012.md)     \n[Youtube](https://www.youtube.com/watch?v=P66h8D5Lkwk)         \n[Wikipedia](https://en.wikipedia.org/wiki/Turing_machine)       \n[Turing1936](reference/Turing1936.md)\n",
    "lastmodified": "2023-07-01T12:55:12.931828154+02:00",
    "tags": null
  },
  "/concept/computability": {
    "title": "computability",
    "content": "\nThree notions of computability for a function are equivalent: \n- The existence of a [Turing machine](concept/Turing%20machine.md) for computing the function.\n- The [abacus](definition/abacus.md)-computability.\n- The fact that the function is a [recursive function](definition/recursive%20function.md).\n\n*A function is computable on a [Turing machine](concept/Turing%20machine.md) if and only if it is a [recursive function](definition/recursive%20function.md).*\n\nSome functions are not computable. \nIndeed, with [Cantor's diagonal argument](concept/Cantor's%20diagonal%20argument.md), we know that the set of [arithmetic function](definition/arithmetic%20function.md)s that have a range on positive integers is not an [enumerable set](definition/enumerable%20set.md). But the set of [Turing machine](concept/Turing%20machine.md)s is an [enumerable set](definition/enumerable%20set.md) (because they can be expressed as quadruplets). Therefore, there are functions that are not computable. \nFor instance, solving the [halting problem](concept/halting%20problem.md) requires the introduction of the halting function that is not computable. \n\n#### Sources \n\n[Boolos2007](reference/Boolos2007.md)\n",
    "lastmodified": "2023-07-01T12:55:09.685864297+02:00",
    "tags": null
  },
  "/concept/protein-folding-problem": {
    "title": "protein folding problem",
    "content": "\nHow does a protein folds ? Levinthal's paradox states that if the protein tries all configurations, it will take forever.  However, it does fold.   [Zwanzig1992](reference/Zwanzig1992.md) ‚Äúsolved‚Äù this paradox stating that if there are small kinetical biased along the trajectory of around $k_BT$, then it can fold on biological relevant time scales. \n\n[Anfinsen's dogma](concept/Anfinsen's%20dogma.md) makes this problem an NP-hard mathematical problem. It is neverthelelss limited because environmental contributions (solvent, [molecular chaperon](definition/molecular%20chaperon.md), the possibility of multiple conformations) are discovered.\n",
    "lastmodified": "2023-07-01T13:02:37.524301353+02:00",
    "tags": null
  },
  "/concept/second-principle-of-thermodynamics": {
    "title": "second principle of thermodynamic",
    "content": "\nThe [entropy](definition/entropy.md) of a **closed system** with **fixed volume** can only increase. \n\nIt is maximum at equilibrium for a system at constant energy. In other words, the system evolves (if not already equilibrated) towards the macro-state that is invariant under the most number of microstates. \n\nThe first law of thermodynamic is the conservation of energy (electric, kinetic, mechanical, chemical,...). The second says that, without external aid, there is a \"dispersion of energy\" such that it tends to make the distribution of energy homogeneous. \n\n",
    "lastmodified": "2023-07-01T13:01:39.134538653+02:00",
    "tags": null
  },
  "/definition/entropy": {
    "title": "entropy",
    "content": "\nFor a given phase space, Hamiltonian and energy, entropy quantifies the number of micro-states available.\n\n#### Details \n\nIn the Gibbs (canonical) ensemble (NVT), the partition function reads $$ Z = \\sum_i e^{-\\beta E_i} $$an with the probability of the micro-state $i$  being  $p_i=e^{-\\beta E_i} / Z$, we have \n$$ S_G=-k_B \\sum_i p_i \\log(p_i) $$\n\nFor a fixed energy, in the micro-canonical ensemble (NVE), the energy is fixed and we get $$ \\Omega = \\sum_i 1 $$ and Boltzmann's entropy  $$ S_B = k_B \\log(\\Omega )$$They are equal by restricting the sum for a given energy $E$ in the summation of the (NVT) ensemble. It gives $Z=e^{-\\beta E}\\Omega$ and $S_G = S_B$.\n",
    "lastmodified": "2023-07-01T13:05:53.496778179+02:00",
    "tags": null
  },
  "/definition/negentropy": {
    "title": "negentropy",
    "content": "\nFirst mentionned in [Schrodinger1944](reference/Schrodinger1944.md) to characterize living systems, it is rigourously introduced by [Brillouin1951](reference/Brillouin1951.md) to relate it to the opposite of [entropy](definition/entropy.md) and positively to information (see [Brillouin's relation between entropy and information](concept/Brillouin's%20relation%20between%20entropy%20and%20information.md)). Providing the ad-hoc homogeneity, it reads $$N=-S= I$$\n#### Sources \n\n[Brillouin1956](reference/Brillouin1956.md)\n",
    "lastmodified": "2023-07-01T13:00:05.756015965+02:00",
    "tags": null
  },
  "/note/note-on-Longo2012": {
    "title": "note on Longo2012",
    "content": "\n## **Is Information a proper observable for biological organization?**     \nby Longo G., Miquel P., Sonnenschein C., Soto A.M. (2012)   \n*Progress in biophysics and molecular biology* 109: 108-114      \nDOI: 10.1016/j.pbiomolbio.2012.06.004\n\nReference: [Longo2012](reference/Longo2012.md)\n\n#### The central dogma of biology was formulated during the thriving era of computer programs.\nThe concepts of [computability](concept/computability.md) and the one of the elaboration of information (reading, writing) with [Turing machine](concept/Turing%20machine.md)s were developed in 1930-1936. In 1944, [Schrodinger's code-script aperiodic crystal](concept/Schrodinger's%20code-script%20aperiodic%20crystal.md) first hint at *informational* content in chromosomes in 1944 ([Schrodinger1944](reference/Schrodinger1944.md)). The discovery of DNA by Crick and Watson in 1953 happened just after this flourishing era of computation and [Crick's central dogma](concept/Crick's%20central%20dogma.md) of molecular biology explained [Mendelian inheritance](concept/Mendelian%20inheritance.md) with the four bases discovered in the DNA in terms of transmission of information from DNA to proteins.\n\n#### The informational metaphor prompts biologist to think about biological phenomena in terms of programs.\n[Crick's central dogma](concept/Crick's%20central%20dogma.md) relies on an informational metaphor and states linear causation from the DNA to the proteins. However, it is a misleading metaphor because it forces the way to think about biological problems. Indeed, most biologists see the genome as the \"program\" for producing proteins. This view ignore the materiality of living organisms, because the software should works on all hardwares in this framework. For instance, Maynard-Smith (that tries to explicitate the notion of information in biology without managing to distinguish Turing and Shannon's difference between elaboration and transmission of information) states:\n\n\u003e [!quote] \n\u003e\n\u003eThere is, however, one feature of the control of development which closely resembles both a computer program, and verbal instructions. This is the symbolic nature of the process (...) ‚Äî  ([MaynardSmith1999](reference/MaynardSmith1999.md), p. 398)  \n\n#### However, programs rely on a very specific structure of determination...\nProgramming or encoding/decoding in cryptography implies the writing and reading of **symbols** on **discrete** entities. The concept of [computability](concept/computability.md) requires **identical iterations**, **portability** (software on hardware), **linear causation**, **predictability** (because of discreteness) and therefore implies [Laplacian determinism](concept/Laplacian%20determinism.md). \n\n#### ...and the concept of information is at best vague in biology\nInformation is not well-defined in biology, but it also has an ambiguous link with [entropy](definition/entropy.md) that play a major role in biology. Following [Brillouin's relation between entropy and information](concept/Brillouin's%20relation%20between%20entropy%20and%20information.md), information is linked to [negentropy](definition/negentropy.md) as:  `high information = low entropy` . On the other hand, following [Kolmogorov's incompressibility](concept/Kolmogorov's%20incompressibility.md) and [Chaitin's algorithmic randomness](concept/Chaitin's%20algorithmic%20randomness.md) interpretation, we obtain `low compressibility = high randomnness` . If we now follow two common interpretations, which are `high information = low compressibility`, and  `high randomnness = high entropy`,  we get a contradiction with [Brillouin's relation between entropy and information](concept/Brillouin's%20relation%20between%20entropy%20and%20information.md). Yet, as pointed out by Schr√∂dinger, it seems that organisms manage to \"resist\" the [second principle of thermodynamics](concept/second%20principle%20of%20thermodynamics.md) so nothing is absurd here, but everything is vague. \n\n#### This structure of determination is an epistemological bias for biologists.\nThe DNA \"software\" taken from one cell (the \"hardware\") is not portable. For example, cloning has a very low success and need to resort to \"epigenetics reprogramming\" ([Matoba2018](reference/Matoba2018.md)). From this perspective, it is, however, possible for humans to \"reprogram\" evolution ([Doudna2017](reference/Doudna2017.md), [Longo2021](reference/Longo2021.md)). The informational metaphor encourages the observer to think in terms of discrete entities. However, there is no Turing's architect and robust, iterative steps.  Yet, molecules play the role of discrete entities containing information. The arguments use the vocabulary such as \"signals\", \"activator-receptor\", or \"docking\".  However, the use of the notion of [computability](concept/computability.md) in biology cannot account for continuous shape deformation. Therefore, continuous shapes are not considered.  Moreover, what is present along with an informational content but cannot be digitally encoded in signs is inherently considered as noise in [Shannon's theory of information transmission](concept/Shannon's%20theory%20of%20information%20transmission.md).  It therefore contributes to deteriorate the informational content due to the information-theoretic application of the [second principle of thermodynamics](concept/second%20principle%20of%20thermodynamics.md). \n\n\u003e [!quote] \n\u003e\n\u003eIf a wire or a computer are compressed, pulled or twisted, these actions will not increase the information that they are transmitting or elaborating, neither in practice nor in principle. ‚Äî  ([Longo2012](reference/Longo2012.md), p. 6) \n\n For example, [Anfinsen's dogma](concept/Anfinsen's%20dogma.md) has narrowed the research activity regarding the [protein folding problem](concept/protein%20folding%20problem.md). Moreover, [Crick's central dogma](concept/Crick's%20central%20dogma.md) suggests that isogenic cells are identical whereas protein and mRNA copy numbers vary from cell to cell, and are uncorrelated in the same cell ([Taniguchi2010](reference/Taniguchi2010.md)).  Biomechanical forces (themodynamics forces, tensions, stresses) are therefore ignored in this framework, although crucial. There is no space and time in this framework. \n\n\n\n\n",
    "lastmodified": "2023-07-01T13:04:30.610959941+02:00",
    "tags": null
  },
  "/reference/Doudna2017": {
    "title": "Doudna2017",
    "content": "\n#### **A crack in creation: The new power to control evolution**     \nby Doudna J., Sternberg S. (2017)         \nRandom House      \n\n\n",
    "lastmodified": "2023-07-01T13:01:57.289119573+02:00",
    "tags": null
  },
  "/reference/Longo2012": {
    "title": "Longo2012",
    "content": "\n#### **Is Information a proper observable for biological organization?**     \nby Longo G., Miquel P., Sonnenschein C., Soto A.M. (2012)         \n*Progress in biophysics and molecular biology* 109: 108-114       \nDOI: 10.1016/j.pbiomolbio.2012.06.004     \n\n**Abstract**:  In the last century, jointly with the advent of computers, mathematical theories of information were developed. Shortly thereafter, during the ascent of molecular biology, the concept of information was rapidly transferred into biology at large. Several philosophers and biologists have argued against adopting this concept based on epistemological and ontological arguments, and also, because it encouraged genetic determinism. While the theories of elaboration and transmission of information are valid mathematical theories, their own logic and implicit causal structure make them inimical to biology, and because of it, their applications have and are hindering the development of a sound theory of organisms. Our analysis concentrates on the development of information theories in mathematics and on the differences between these theories regarding the relationship among complexity, information and entropy.\n\n\n\n\u003e [!quote] \n\u003e\n\u003eIf a wire or a computer are compressed, pulled or twisted, these actions will not increase the information that they are transmitting or elaborating, neither in practice nor in principle. ‚Äî  (Longo et al., 2012, p. 6) \n\n\n\n",
    "lastmodified": "2023-07-01T13:04:52.792407002+02:00",
    "tags": null
  },
  "/reference/Longo2021": {
    "title": "Longo2021",
    "content": "\n#### **Programming Evolution: A Crack in Science**     \nby Longo G. (2021)         \nDOI: 10.13133/2532-5876/17538     \n\n**Abstract**:  Nobel Prize winner, Jennifer Doudna, and Samuel Sternberg survey recent advances in a pioneering area of molecular biology. In an accessible and elegant style, the authors present the successes and challenges of a new DNA-modifying technique: CRISPR. They transmit their emotions of discovery, passion for research, and intellectual audacity. While greatly admiring the technical skills of the authors, who are among the best researchers in the field, this review critically stresses the limits of their experimental practices, namely: a vague or incomplete theoretical frame; often unreachable genetic targets; off-target effects; prior failures to deliver by other forms of genetic manipulation, and, finally, the intrinsic unpredictability of many phenotypic consequences of such a powerful technique. Due to these concerns, the authors‚Äô approach to organisms and Evolution is questioned with the purpose to generate an open debate.\n\n",
    "lastmodified": "2023-07-01T13:02:02.730989113+02:00",
    "tags": null
  },
  "/reference/Matoba2018": {
    "title": "Matoba2018",
    "content": "\n#### **Somatic Cell Nuclear Transfer Reprogramming: Mechanisms and Applications**     \nby Matoba S., Zhang Y. (2018)         \n*Cell Stem Cell* 23: 471-485       \nDOI: 10.1016/j.stem.2018.06.018     \n\n\n",
    "lastmodified": "2023-07-01T13:01:50.991275471+02:00",
    "tags": null
  },
  "/reference/MaynardSmith1999": {
    "title": "MaynardSmith1999",
    "content": "\n#### **The Idea of Information in Biology**     \nby Maynard Smith J. (1999)         \n*The Quarterly Review of Biology* 74: 395-400       \nDOI: 10.1086/394109     \n\n\n\u003e [!quote] \n\u003e\n\u003e*There is, however, one feature of the control of development which closely resembles both a computer program, and verbal instructions. This is the symbolic nature of the process* ‚Äî  (Maynard Smith, 1999, p. 398)  \n \n\n\n",
    "lastmodified": "2023-07-01T12:59:04.865181461+02:00",
    "tags": null
  },
  "/reference/Schrodinger1944": {
    "title": "Schrodinger1944",
    "content": "\n#### **What is Life?: With Mind and Matter and Autobiographical Sketches**     \nby Schr√∂dinger E. (1944)         \nCambridge University Press      \n\n**Abstract**:  Nobel laureate Erwin Schr√∂dinger's What is Life? is one of the great science classics of the twentieth century. A distinguished physicist's exploration of the question which lies at the heart of biology, it was written for the layman, but proved one of the spurs to the birth of molecular biology and the subsequent discovery of the structure of DNA. The philosopher Karl Popper hailed it as a 'beautiful and important book' by 'a great man to whom I owe a personal debt for many exciting discussions'. It appears here together with Mind and Matter, his essay investigating a relationship which has eluded and puzzled philosophers since the earliest times. Schrodinger asks what place consciousness occupies in the evolution of life, and what part the state of development of the human mind plays in moral questions. Brought together with these two classics are Schr√∂dinger's autobiographical sketches, published and translated here for the first time. They offer a fascinating fragmentary account of his life as a background to his scientific writings, making this volume a valuable additon to the shelves of scientist and layman alike.\n\n",
    "lastmodified": "2023-07-01T12:58:02.715989793+02:00",
    "tags": null
  },
  "/reference/Taniguchi2010": {
    "title": "Taniguchi2010",
    "content": "\n#### **Quantifying E. coli Proteome and Transcriptome with Single-Molecule Sensitivity in Single Cells**     \nby Taniguchi Y., Choi P.J., Li G., Chen H., Babu M., Hearn J., Emili A., Xie X.S. (2010)         \n*Science* 329: 533-538       \nDOI: 10.1126/science.1188308     \n\n\n",
    "lastmodified": "2023-07-01T13:02:46.262136059+02:00",
    "tags": null
  }
}