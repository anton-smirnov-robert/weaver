
---
title: "principle of variation from physics"
date: 2023-04-06
draft: false
showthedate: true
enabletoc: true
draft: true
tags:
- literature-note
---

In the framework of statistical mechanics, we model a generic organism and its environment that are enclosed in a dome large enough for it not to notice. I call this system the Truman system in the following. We consider the phase space as the position and momenta of all atoms in this global system. An equation governs the trajectory of the system's state, starting from a state corresponding to living organism and an appropriate environnement state. The trajectory is deterministic but unpredictable to us for epistemic reasons—we are not Laplacian deamons. 

In the phase space, the volume of the set of microstate configurations (macrostate) in which the organism under scrutiny lives is extremly small with respect to the one where it is dead. 
Indeed, there are a lot more atomic configurations for which the organism is dead, for instance when its atoms are scattered. The most probable macrostate being "death", an organism will eventually die according to the second law of thermodynamics. This is indeed what we observe. The system takes a *lifetime* to access for the first time the largest macrostate of the system that we can label "death". Also, we usually don't come back from this first incursion in the "death" macrostate. Similarly, particles in a box initially placed in one corner spread rapidly in the entire box, but do not go back in the corner. We would have to wait a incredible amount of time for it to happen.

Actually, we would definetly not see this happening in the real life. This is because we already made an implicit assumption regarding the time scale on which our model is valid. As Richard Feynman puts it, thermal equilibrium is when "all 'fast' things have happened *and* all the "slow" things not" ([Feynman1972](reference/Feynman1972.md)) — my emphasis. Indeed, in modelling closed systems, we assume that when equilibrium, is reached, the system will remain in this macrostate *ad eternum*. However, in real systems, this is not the case. If all closed systems eventually end up at equilibrium (the second law), the state of the closed system which contains the first one needs also to go towards the most probable configurations. For instance, the box which contains the particles, *must* eventually fall apart — because it is made of atoms— if we look at the largest system. Therefore, all closed systems that contain each other cannot stay at equilibrium *ad eternum*. In fact, what happens is that the *description* of the smaller system is no longer valid at a given point because something that was not predefined in the phase space happens (particles exit the box). Note that this is of course not restricted to closed systems. Invariant materials entities in open systems also obey the second law in a larger closed system. This assumption is therefore valid solely for a limited amount of time $\tau_{\mathrm{valid}}$. We have understood what the famous physicist means about the "slow" things not happening. 

Equilibrium can only be reached —for a limited amount of time $\tau_{\mathrm{valid}}$ — in closed systems. Equilibrium statistical mechanics is about measuring observables that are averages over the entire phase space. In practice, we access those properties with our instruments by letting the system evolve by itself and by measuring the quantities we observe. If the system visit the different macrostates of the phase space for a duration that is roughly proportional to their volume, one can compute the phase space average as a time average. In fact, it is not obvious that the system *can* visit all macrostates starting from a "typical" point, and one usually takes this as granted by making the ergodic hypothesis. In any case, a necessary condition for equilibrium to be reached is that the system enters a macrostate that have a non-negligeable volume for some time. For instance, the macrostate corresponding to particles placed in a corner of a box have a negligeable weight in the phase space integral because its volume is negligeable. Accordingly, if you initially put the system in this singular macrostate, it will exit it "fast" and this will have little impact on your time-average *if* you wait a relatively long time after that. We now understand what Feynman means by the requirement regarding 'fast' things having happened for thermodynamic equilibrium to be reached.

Let's sum up. Models using statistical mechanics are always bounded in time because they assume that "slow" things do not happen. This is usually left implicit by the modeler which implicitely relies on invariant material entities that can be rigthfully considered as such *for a limited amount of time* $\tau_{\mathrm{valid}}$. Equilibrium statistical mechanics requires that we observe the system for a time $\tau_{\mathrm{eq}}$  that is way larger than the time scale on which the system exit the improbable macrostates. Coming back to the Truman system, we have seen that if we wait long enough to reach the largest macrostate of the system, the organism is dead. In other word, noting $\tau_{\mathrm{org}}$  the *relevant time of observation* for organisms —a lifetime —, we have $\tau_{\mathrm{org}} <  \tau_{\mathrm{eq}}.$ What is interesting for biology in this huge physicaal system happens *out-of-equilibrium*. Of course, we can safely consider that the dome will not be damaged during the lifetime of the organism: $\tau_{\mathrm{org}} \ll  \tau_{\mathrm{valid}}.$ 

We now zoom in the "alive" macrostate, which predefines all the ways an organism can be alive[^1]. Suppose we have a physico-mathematical apparatus whose new phase space is the "alive" macrostate. The new equation maps the global one on the "alive" macrostate *except* on its borders — because the second equation cannot make the system escape the predefined space of possibilities. Considering the tremendous reduction of the phase space, the theoretical move cannot be discarded despite the obvious problems of continuity between the two physico-mathematical structures. Besides, one should remember that the trajectory on the global phase space is unpredictable for practical reasons and that the value of epistemic insights that can be harnessed for biology are quasi-null at this level. Therefore, on the one hand, we have the global physical system described by an immense phase space, and where we know that a living organism will eventually enter the preponderant macrostate labelled "death". On the other hand, we have the local biological system caracterized by a more practical and smaller set of possibilities which reduce the immense and useless (from a biological perspective) "death" macrostate. However, adopting this approach requires predefining possibilities in which the death state cannot be accomodated, by construction. Choosing one of both physico-mathematical comes at a price. 

In sum, *if we give up on trying to understand the deterministic but unpredictable trajectory of an organism in the huge physical system, we need to adopt the physico-mathematical structure of the biological system while knowing that it will no longer be valid after a time scale $\tau_{\mathrm{org}}$.* It looks like if we choose this perspective, our describtion becomes fragile, because we cannot rely on an uniquely valid physico-mathematical structure to describe the evolution of an organism. Yet, this is similar to the usual limited range of validity of models in statistical mechanics ( $\tau_{\mathrm{valid}}$ ). In fact, if one could link $\tau_{\mathrm{org}}$ to the time scale of degradation of material entities that constrain the system to remain in the "alive" macrostate, then we would not do something any different from a conceptually. In general, we can argue that organisms are delimited from their environment by semi-permeable membranes and that their irreversible degradation leads to death. Therefore, we can adopt our new and simpler physico-mathematical structure defined on the "alive" macrostate alone, using $\tau_{\mathrm{valid}}=\tau_{\mathrm{org}}$ .

We now characterize the trajectory of an organism in this biological system. We make a coarse-graining of this system by labelling regions corresponding to say species. An organism does not go through all living macrostates before dying. For instance, an elephant does not become a cornflower, then a rat, then a diplodocus, and finally an *E.coli* bacteria before dying. In other words, an organism spends its lifetime in a very restricted part of the living possibilities. The notion of equilibrium is not adequate in this phase space because death is not in it. Rather, it is the concept of ergodicty that is relevant here. The system does not visit all macrostates during the time our physico-mathematical description is valid. Therefore, we can firmly state that our biological system is highly non-ergodic. 

Let's extend the time scale of validity of our physico-mathematical description by allowing the organism to reproduce. This needs some precisions. First, organisms are independent and they all live without interacting with one another. Second, we consider that offsprings branch the current state of the parent trajectory. Why? Well, dogs don't make cats. The trajectories of the parent and the offsprings should be *relatively close* to one another. I consider they (nearly) touch each other when the parent reproduce. With those assumptions, we can consider that our physico-mathematical description of the biological space allows us to follow unpredictable trajectories for about $\tau_{\mathrm{bio}}\sim 3.5 \times 10^9$ years, the estimated duration of life on Earth so far. 

Have all possibilities of living organisms been explored since the first living beings appeared on Earth? Darwin first understood that the myriad of life forms we can observe nowadays were not created at once, but had a common origin. Their unbounded diversification on the time scale of $\tau_{\mathrm{bio}}$  comes from the phenomenon of "descent with modification". In other words, the idea of an *open-ended evolution* —scientifically supported for the past and that we have all reasons to believe that it is still occuring— is equivalent to saying that our biological system is not ergodic as far as we know. It keeps exploring new part of the biological phase space, and it may not explore them all if all kinds of life forms disappear.

Because life forms are continuously exploring new part of the immense biological phase space at the time scale of $\tau_{\mathrm{bio}}$, organisms must do the same at the time scale $\tau_{\mathrm{org}}$. This has a crucial consequences regarding tractable physico-mathematical description of organisms. Indeed, tractable biophysical models need to restrict their range of validity to specific organisms, usually grouped in taxa, because the diversity of life forms is too large. In doing so, they are investigating specific zones of the biological phase space to reduce the complexity of models. In fact, the more restricted the zone is, the more precise the model can be, but the less general the contribution is. How are those zones chosen? Positing a phase space means predefining a set of possibilities, but we have just seen that the latter *must* change on the time scale of a lifetime. Should we need to change our models everytime an organism dies?

e have just underlined that organisms must explore new parts of the biological space *on the time scale of $\tau_{\mathrm{org}}$.* Should we revise our models every time an organism dies? 

By tractable models, we mean that. Indeed, tractable physico-mathematical models in biology are usually describing a part of a known and specific organism, say the leg of an elephant. More precisely, several models can be used to describe development, and they are all valid for a limited amount of time. For instance, the bone can described as an invariant rigid entity at short time scales, but it can also be variable when studying how it is formed. In any case, because organisms evolve, one needs to use a *succession* of physico-mathematical models whose range of validity is limited. However, and this is m

quantity that allows the squeletton to be formed.

Following to the above-mentionned strategy for describing an organism, we may want to zoom in the biological system and create physico-mathematical apparatuses dedicated to describe all *taxa*, keeping in mind that they would be valid on a time scale of $\tau_{\mathrm{org}}$. We call those smaller systems the *taxon system*. In fact, a macrostate defining a taxon can be again splitted into several stages of development. We would then build a *predefined succession* of $N$ physico-mathematical structures, respectively valid on a time scale $\tau_i$ for $1\leq i\leq N$ and $\sum_i\tau_i\simeq \tau_{\mathrm{org}}$, to describe the lifetime of an organism that belong to this taxon. However, this would not be compatible with the emergence of new life forms during evolution because organisms would not explore zones that are not part of the set of *taxon system*s, however rich the description may be.  

In sum, the observation of the open-ended evolution at the time scale $\tau_{\mathrm{bio}}$  requires that organisms cannot be described by predefined physico-mathematical structures at the time scale $\tau_{\mathrm{org}}$. *Mutadis mutandis*, developmental stages of organisms cannot be described by a succession of predefined physico-mathematical structures. If we want to get a better understanding of an organism and reduce the dimensionality of the phase space in which we describe its state, we are compelled to acknowledge that the validity of the physico-mathematical structure we use is limited in time *and* that we cannot predict the one that we shall adopt next. Here, we face a strongest form of randomness: we do not know when our description is no longer valid and we cannot prestate what comes next, by principle. Of course, there is an apparent directionality, and most organisms follow similar stages of development. But predefining a sequence of stages to describe an organism contradicts the observation of a an open-ended evolution. Directionality must be explained, and not posited. More generally, we will describe parts of an organism by mathematical structures that are valid on a given timescale $\tau$. This decomposition allows us to change parts of the organism one by one instead of the entire description. 

Let's conclude, the physico-mathematical structure to describe an organism is not stable with respect to the flow of time, and change in an unpredictable way. An organism results from a history of unpredictable changes of physico-mathematical structures. Because, of this strong randomness, organisms all differ *qualitatively* by principle. ==Organisms are specific objects.==


- Genealogy is a precious reference point! (identity of organisms)






Propagating the trajectory of the time scale of some minutes, hours, or even years would most probably not kill our generic organism. 
This is actually what we can observe for most organisms on a daily basis.
- Need to explain closure.([Schrodinger1944](reference/Schrodinger1944.md)).
Now, according to Boltzmann reasonning, the larger the volume of the most probable macrostate, the faster you get to it. 
An estimation for the bacteria *E.coli*:   $2^{4.6\times 10^{10}}$[Morowitz1955a](reference/Morowitz1955a.md)
So how fast can we expect an organism to go to it? We will come back to this. 






[^1]: Of course, we face major difficulties in practice to define such a macrostate because we do not *understand* the living attribute of an organism based on its atomic positions and velocities. However, it can be defined in principle, at least as the states in the phase space that points to configurations of atoms that a human would recognize as alive. 

