
---
title: "principle of variation from physics"
date: 2023-04-06
draft: false
showthedate: true
enabletoc: true
draft: true
tags:
- literature-note
---

In the framework of statistical mechanics, we model a generic organism and its environment that are enclosed in a dome large enough for it not to notice. I call this system the Truman system in the following. We consider the phase space as the position and momenta of all atoms in this global system. An equation governs the trajectory of the system's state, starting from a state corresponding to living organism and an appropriate environnement state. The trajectory is deterministic but unpredictable to us for epistemic reasons—we are not Laplacian deamons. 

In the phase space, the volume of the set of microstate configurations (macrostate) in which the organism under scrutiny lives is extremly small with respect to the one where it is dead. 
Indeed, there are a lot more atomic configurations for which the organism is dead, for instance when its atoms are scattered. The most probable macrostate being "death", an organism will eventually die according to the second law of thermodynamics. This is indeed what we observe. The system takes a *lifetime* to access for the first time the largest macrostate of the system that we can label "death". Also, we usually don't come back from this first incursion in the "death" macrostate. Similarly, particles in a box initially placed in one corner spread rapidly in the entire box, but do not go back in the corner. We would have to wait a incredible amount of time for it to happen.

Actually, we would definetly not see this happening in the real life. This is because we already made an implicit assumption regarding the time scale on which our model is valid. As Richard Feynman puts it, thermal equilibrium is when "all 'fast' things have happened *and* all the "slow" things not" ([Feynman1972](reference/Feynman1972.md)) — my emphasis. Indeed, in modelling closed systems, we assume that when equilibrium, is reached, the system will remain in this macrostate *ad eternum*. However, in real systems, this is not the case. If all closed systems eventually end up at equilibrium (the second law), the state of the closed system which contains the first one needs also to go towards the most probable configurations. For instance, the box which contains the particles, *must* eventually fall apart — because it is made of atoms— if we look at the largest system. Therefore, all closed systems that contain each other cannot stay at equilibrium *ad eternum*. In fact, what happens is that the *description* of the smaller system is no longer valid at a given point because something that was not predefined in the phase space happens (particles exit the box). Note that this is of course not restricted to closed systems. Invariant materials entities in open systems also obey the second law in a larger closed system. This assumption is therefore valid solely for a limited amount of time $\tau_{\mathrm{valid}}$. We have understood what the famous physicist means about the "slow" things not happening. 

Equilibrium can only be reached —for a limited amount of time $\tau_{\mathrm{valid}}$ — in closed systems. Equilibrium statistical mechanics is about measuring observables that are averages over the entire phase space. In practice, we access those properties with our instruments by letting the system evolve by itself and by measuring the quantities we observe. If the system visit the different macrostates of the phase space for a duration that is roughly proportional to their volume, one can compute the phase space average as a time average. In fact, it is not obvious that the system *can* visit all macrostates starting from a "typical" point, and one usually takes this as granted by making the ergodic hypothesis. In any case, a necessary condition for equilibrium to be reached is that the system enters a macrostate that have a non-negligeable volume for some time. For instance, the macrostate corresponding to particles placed in a corner of a box have a negligeable weight in the phase space integral because its volume is negligeable. Accordingly, if you initially put the system in this singular macrostate, it will exit it "fast" and this will have little impact on your time-average *if* you wait a relatively long time after that. We now understand what Feynman means by the requirement regarding 'fast' things having happened for thermodynamic equilibrium to be reached.

Let's sum up. Models using statistical mechanics are always bounded in time because they assume that "slow" things do not happen. This is usually left implicit by the modeler which implicitely relies on invariant material entities that can be rigthfully considered as such *for a limited amount of time* $\tau_{\mathrm{valid}}$. Equilibrium statistical mechanics requires that we observe the system for a time $\tau_{\mathrm{eq}}$  that is way larger than the time scale on which the system exit the improbable macrostates. Coming back to the Truman system, we have seen that if we wait long enough to reach the largest macrostate of the system, the organism is dead. In other word, noting $\tau_{\mathrm{org}}$  the *relevant time of observation* for organisms —a lifetime —, we have $\tau_{\mathrm{org}} <  \tau_{\mathrm{eq}}.$ What is interesting for biology in this huge physicaal system happens *out-of-equilibrium*. Of course, we can safely consider that the dome will not be damaged during the lifetime of the organism: $\tau_{\mathrm{org}} \ll  \tau_{\mathrm{valid}}.$ 

We now zoom in the "alive" macrostate, which predefines all the ways an organism can be alive[^1]. Suppose we have a physico-mathematical apparatus whose new phase space is the "alive" macrostate. The new equation maps the global one on the "alive" macrostate *except* on its borders — because the second equation cannot make the system escape the predefined space of possibilities. Considering the tremendous reduction of the phase space, the theoretical move cannot be discarded despite the obvious problems of continuity between the two physico-mathematical structures. Besides, one should remember that the trajectory on the global phase space is unpredictable for practical reasons and that the value of epistemic insights that can be harnessed for biology are quasi-null at this level. Therefore, on the one hand, we have the global physical system described by an immense phase space, and where we know that a living organism will eventually enter the preponderant macrostate labelled "death". On the other hand, we have the local biological system caracterized by a more practical and smaller set of possibilities which reduce the immense and useless (from a biological perspective) "death" macrostate. However, adopting this approach requires predefining possibilities in which the death state cannot be accomodated, by construction. Choosing one of both physico-mathematical comes at a price. 

In sum, *if we give up on trying to understand the deterministic but unpredictable trajectory of an organism in the huge physical system, we need to adopt the physico-mathematical structure of the biological system while knowing that it will no longer be valid after a time scale $\tau_{\mathrm{org}}$.* It looks like if we choose this perspective, our describtion becomes fragile, because we cannot rely on an uniquely valid physico-mathematical structure to describe the evolution of an organism. Yet, this is similar to the usual limited range of validity of models in statistical mechanics ( $\tau_{\mathrm{valid}}$ ). In fact, if one could link $\tau_{\mathrm{org}}$ to the time scale of degradation of material entities that constrain the system to remain in the "alive" macrostate, then we would not do something any different from a conceptually. In general, we can argue that organisms are delimited from their environment by semi-permeable membranes and that their irreversible degradation leads to death. Therefore, we can adopt our new and simpler physico-mathematical structure defined on the "alive" macrostate alone, using $\tau_{\mathrm{valid}}=\tau_{\mathrm{org}}$ .

We now characterize the trajectory of an organism in this biological system. We make a coarse-graining of this system by labelling regions corresponding to say species. An organism does not go through all living macrostates before dying. For instance, an elephant does not become a cornflower, then a rat, then a diplodocus, and finally an *E.coli* bacteria before dying. In other words, an organism spends its lifetime in a very restricted part of the living possibilities. The notion of equilibrium is not adequate in this phase space because death is not in it. Rather, it is the concept of ergodicty that is relevant here. The system does not visit all macrostates during the time our physico-mathematical description is valid. Therefore, we can firmly state that our biological system is highly non-ergodic. 

Let's extend the time scale of validity of our physico-mathematical description by allowing the organism to reproduce. This needs some precisions. First, organisms are independent and they all live without interacting with one another. Second, we consider that offsprings branch the current state of the parent trajectory. Why? Well, dogs don't make cats. The trajectories of the parent and the offsprings should be *relatively close* to one another. I consider they (nearly) touch each other when the parent reproduce. With those assumptions, we can consider that our physico-mathematical description of the biological space allows us to follow unpredictable trajectories for about $\tau_{\mathrm{bio}}\sim 3.5 \times 10^9$ years, the estimated duration of life on Earth so far. 

Have all possibilities of living organisms been explored since the first living beings appeared on Earth? Darwin first understood that the myriad of life forms we can observe nowadays were not created at once, but had a common origin. Their unbounded diversification on the time scale of $\tau_{\mathrm{bio}}$  comes from the phenomenon of "descent with modification". In other words, the idea of an *open-ended evolution* —scientifically supported for the past and that we have all reasons to believe that it is still occuring— is equivalent to saying that our biological system is not ergodic as far as we know. It keeps exploring new part of the biological phase space, and it may not explore them all if all kinds of life forms disappear. This has a crucial consequences regarding tractable physico-mathematical description of organisms.

Biophysical models that represent (all parts of) organisms and their environment usually need to focus on a very restricted zone of the biological phase space because life forms are too diverse and complex to be correctly accomodated by one physico-mathematical structure. The more restricted the zone is, the more precise the model can be, but the less general the epistemic contribution is. The limit is to model only one specific organism, for exemple me at this precise instant. In practice, we want to extend that singular zone of the biological phase space to accomodate at least some quantitative variations. Nevertheless, how is the zone chosen for a generic organism? Life forms are continuously and unpredictably exploring *new* parts of the immense biological phase space at the time scale of $\tau_{\mathrm{bio}}$. Therefore, organisms *must* do the same during their lifetime. In other words, the biophysical phase spaces that grounds biophysical models of generic organisms cannot be predefined once and for all and their validity is restricted to a time scale $\tau_{\mathrm{org}}$ . If we use a *succession* of biophysical models to describe the development of an organism, this succession cannot be *predefined*. Doing so amounts to adopt a fixist perspective or to affirm that we know where evolution is going. 

If we need a biophysical model for each organism and that the latter needs to be changed during its lifetime, are biophysical models useful at all? No, if we need to rebuild them from scratch every time. This would be too much work given the complexity of living beings. However, if we rely on the fundamental but supported hypothesis that posit a ressemblance between parents and offsprings, it is no longer the case. In that case, we can rather focus on *differences* between offsprings and parents. The parent is like a reference in this vast non-ergodic system, and we modify it to describe the offspring. Of course, parents are also defined with respect to their past ancestors. Therefore, we are mixing to epistemologies: we define an organism by referring to its genealogy *and* some physico-mathematical models! Each organism has its specific (contextual) history. ==Organisms are specific and historical objects that vary in upredictable ways, by principle.== The question is why do organisms look alike? What does some life forms seem to be stabilized?




Propagating the trajectory of the time scale of some minutes, hours, or even years would most probably not kill our generic organism. 
This is actually what we can observe for most organisms on a daily basis.
- Need to explain closure.([Schrodinger1944](reference/Schrodinger1944.md)).
Now, according to Boltzmann reasonning, the larger the volume of the most probable macrostate, the faster you get to it. 
An estimation for the bacteria *E.coli*:   $2^{4.6\times 10^{10}}$[Morowitz1955a](reference/Morowitz1955a.md)
So how fast can we expect an organism to go to it? We will come back to this. 






[^1]: Of course, we face major difficulties in practice to define such a macrostate because we do not *understand* the living attribute of an organism based on its atomic positions and velocities. However, it can be defined in principle, at least as the states in the phase space that points to configurations of atoms that a human would recognize as alive. 

