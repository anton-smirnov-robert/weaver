
---
title: "note on Montevil2016 and Montevil2022a"
date: 2023-03-24
draft: false
showthedate: true
enabletoc: true
draft: false
tags:
- literature-note
---

#### **Theoretical principles for biology: Variation**     
by Montévil M., Mossio M., Pocheville A., Longo G. (2016)         
*Progress in Biophysics and Molecular Biology* 122: 36-50    

Reference: [Montevil2016](reference/Montevil2016.md)

#### **Historicity at the heart of biology**     
by Montévil M. (2020)         
*Theory in Biosciences* 141: 165-173          

Referenc: [Montevil2020](reference/Montevil2020.md)


### How does physics work? 

Physics uses *generic* objects. They are abstract objects sharing some common *properties* (mass, charge, length, etc. ), and that can be permutated while leaving the scientific rationale invariant. For instance, any abstract object of a mass $m$ is generic, because a shoe and an apple with the same mass are *identical* from the point of view of free fall in classical mechanics.

A mathematical equation governs the dynamics of the *state* of an object in a *predefined* space of pertinent observables (e.g., position, momenta, angle, etc.) called *phase space*. All possibilities are given in advance, and a trajectory is only a partial order indexed by a variable that we call time. Equations are valid in the entire phase space. Therefore, equations are not concerned about the specific values of the object's state or propreties, but rather about the *relations* between those quantities. Most physical properties are actually defined in a relational way (charge, mass, solubility, elasticity, etc.), and we can consider that physics rely on a relational epistemology.

At the core of this physical description of matter lies the cental notion of symmetry, which is invariance under transformation. First, generic objects are symmetric, because they can be permutated while leaving the scientific explanation invariant. Second, the objectivity of phase spaces rely on the invariance of the observables by a suitable transformation of a reference. For instance, Galilean referentials are useful because the dynamics studied in one of them are also valid in others. Lastly, equations are justified using conservation laws that can be linked to  symmetries (Noether's theorem). Fundamentals laws of physics, such as the conservation of energy in mechanics, stem from a time-reversal symmetry. 

In sum, physics understands change (of state of objects) based on invariance (under some transformations). Symmetries are central (for objects, for observables, for time) to extend objectivity by stating what is *identical* (objects, experiments, energy). The trajectory of the state a *generic* object is given as a partial order on a set of pertinent possibilities. It is given by a mathematical equation that is concerned by the differential effect caused by a relation between states and properties of objects, for all possible values defined by the predefined phase space ([Longo2014](reference/Longo2014.md),[VanFraassen1989](reference/VanFraassen1989.md)). 


![](images/Pasted%20image%2020230320111525.png)


### Can physics provide a rigourous framework for biology? 

The objects of biology are organisms, but organisms are not invariant under the flow of time, because they develop and evolve. Therefore, physics cannot use organisms as an object *per se*. In physics, an organisms can only be encountered as result of the interactions between a multitude of invariant objects. However, even cells are created, change, and disappear. Physics must then use sub-cellular elements to describe organisms. While this option is possible in principle, it is far from obvious that it is most practical approach. Pragmatically, physics is still far from being able to understand or model a single cell. Therefore, while being different from physics, an rigorous theoretical frame that uses organisms as objects, could increase objectivity in biology. 

### A sound departure from determinism 

We argue that departing from physics means giving up a deterministic view of biological phenomena. The latter is enshrined in physicalist reductionnism (theories of natural sciences are reducible to those of physics), that usually take two aspects. For neopreformationist, it is complete genetic determinism. Life can be written by combinations of four letters, materialized by nucleotides. Therefore, organisms can be enumerated, and they all preexist. For others, living beings can be understood with the deterministic trajectories of atoms because they are made of such particles. Of course, those two claims are seldom endorsed as such by scientists. Rather, they are moderated by mentioning, for instance, epigenetics in the first case, the impredictibility of quantum mechanics or chaos theory in the second. 

However, in both cases, the limit of this approach does not emerge from the fact that additional effects are ignored (which would make determinism a bad approximation). Rather, it lies in the fact that the chosen observables are not pertinent for the *understanding* of organisms, starting with their viability. A extraordinary small part of those phase spaces are relevant for biology, *as far as we know*. Even if we endorse complete genetic determinism, DNA sequences that program living beings represent an extremely small number of all the ones that can be enumerated. Atomic positions and velocities that can be attribuated to organisms are nearly singularities in the corresponding phase space. Almost all elements of those spaces do not represent an organism (Fig.1a). In physical terms, those spaces are explored by the universe in a strongly non ergodic way ([Kauffman2019](reference/Kauffman2019.md)).

Giving up these kind of descriptions because of their lack of biological meaning, does not imply ignoring their importance in other theoretical frames (e.g., for DNA sequencing, for physics). However, for biology, they only constitute pre-possibilities ([Montevil2019a](reference/Montevil2019a.md), [note on Montévil2019a](note/note%20on%20Montévil2019a.md)). We need to gather some of the biological meaningful pre-possibilities to constitute a subset a pertinent set of possibilities, *as far as we can tell*. This requires finding those singularities in the original phase space (let's say of positions and velocities), redefining the observables[^1] to reconfigure those possibilities in a meaningful smaller set, and zooming in (Fig.1b, first panel)[^3] . 

### Biology is a theoretical sport

Preserving biological meaning by solely considering a relevant set of possibilities comes at a cost. First, adding a possibility in this frameless phase space means having seen it being realized. In other words, the pertinent space of description of organisms is *historical*. Second, adding a new possibility means that the organism has realized this possibility, and that this possibility was not one before that. Therefore, organisms can vary in a fundamentally *unpredictable* way for the theoretical framework. This defines a strong an irreducible notion of randomness in biology (Fig.1b, second panel) Third, because the pertinent observables are established according to the current possibilities, they can also change in time. In sum, the overall mathematical structure that describe an organism change in time (Fig.1b, third panel). 

Let's dwell on this last point. Biophysicists always predefine possibilities for the evolution of the functional parts of organisms — for epistemological reasons. The posited phase space proceed from empirical observations, at a given time (Fig.1c, first panel). However, we have seen that the physico-mathematical modelling of organisms — and *a fortiori* one of its pertinent observable — can only be valid for a finite duration. The simulation of a functional part of an organism, sooner or later, will no longer be valid because the organism is not quantitatively *and* qualitatively invariant in time (Fig.1c, second panel).

In fact, biophysical models often raise an epistemological problem. In fixing values of parameters or initial/boundary conditions to simulate functional parts of an organism, biophysicists seldom justified them with theoretical arguments. This is in contrast with the physical approach, whose objectivity aims to provides general insights about relations between generic objects. It requires discussing a phenomenon for a range of values of parameters to bring epistemic insights ([Montevil2022a](reference/Montevil2022a.md)). For instance, free fall is the physical insight brought by models showing that an object of *any* mass (negligeable compared to the one of Earth), and initially dropped at *any* altitude, end up on the ground.

However, parameters and initial/boundary conditions in biophysical models *are* specific. Yet, they can be understood only in the light of previous models of the organism, that is its history. Moreover, whereas physics relies on a relational epistemology, it does not account for the specific circular organization of the functional parts of an organism that allows it to self-maintain. Therefore, an organicist epistemology requires to resort to the epistemology of history and an epistemology of self-maintaining physical systems. Accordingly, *biological models need to sychronically and diachronically articulate physico-mathematical models of an organism's functional parts* (Fig.1c). 

### A definition of specific objects

From the above-mentionned considerations, we can posit the *principle of variation* ([Montevil2016](reference/Montevil2016.md)): ==organisms are **specific** objects==.

Specific objects undergo *unpredictable* variations that make the mathematical framework that describe them change in time. 
Specific objects cannot be understood without their *history* of variations, that justifies the phase space in which the organism is described. 
Specific objects are *contextual* objects, like generic objects. Yet, due to their historicity, the *contextual history* of specific object matters[^2].  

Specific objects exhibit differences when compared to each other, or with themselves at different time. 
Similarities between two specific objects can only stem from a shared history, more precisely from common descent. 
Specific objects, unlike generic objects, are difficult to abstract from their material instantiations, mainly for epistemic reasons.

Given the principle of variation, the relative regularities of the functional parts of an organism remain to be explained.
We will argue elsewhere that it needs to be explained thanks to the circularity of their organization. 

This principle is inspired by the notion of “descent with modification” of Darwin ([Darwin1859](reference/Darwin1859.md)). Compared to Lamarck, Darwin states that variations come from "chance", they are not directed. The latter would imply a deterministic framework and therefore anhistoricity. Other roots of the idea come from ([Beatty1995](reference/Beatty1995.md)) and ([Gould2002](reference/Gould2002.md)).
Variation, as a principle, does not need a justification. However, one can find it in chaotic processes, random gene expression, cellular proliferation with two non-identical cells, etc...
In contrast to Darwin's idea, variation also occur during ontogenesis (not only for phylogenesis). 


[^1]: It will be argued elsewhere that the pertinent observables for biology are material entities that have a [biological function](concept/biological%20function.md) or that are constrained by them — those term will be defined. In the folllowing, pertinent observables and functional part are synonymous. 

[^2]: For instance, the immune repertoire of mammals depends on a contextual history at the ontogenetic and genealogical time scale. 

[^3]: Note that this is what is done in when organisms are described by genes that are determistically related to biological functions. However, it has been shown that organisms are not solely determined by their genes, and that this correspondance is rather complex, and context-dependent. Moreover, if the human genome is defined by around 25,000 genes, the argument for non-ergodicity regarding the possible combinations of gene networks is the same.