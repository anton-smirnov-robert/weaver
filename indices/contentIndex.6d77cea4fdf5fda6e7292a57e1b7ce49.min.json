{"/":{"title":"complexus","content":"","lastmodified":"2022-12-07T10:54:59.705202183Z","tags":null},"/Where-am-I":{"title":"Where am I?","content":"\nWelcome!\n\nYou are on my personal website. You can find out [about me](about%20me.md) by clicking on the link.\n\nIn fact, this entire website relies on forward and backward links (backlinks) between pages as you can see on the local graph just below. \nAt any moment you can go back to the global graph containing all pages by cliking on **complexus** at the top of the page or **Home** at the bottom.\n\nIf you are here for the first time, let me introduce you to the project in four steps.r\n\n[about the website](about%20the%20website.md)\n\n\u003e[!warning]  \n\u003e\n\u003eCan i say something here ? \n\n\n\n\n","lastmodified":"2022-12-07T10:54:59.705202183Z","tags":null},"/about-me":{"title":"about me","content":"\nI'm Anton Robert. [list of publications](list%20of%20publications.md)\n\n[manifesto](manifesto.md)\n","lastmodified":"2022-12-07T10:54:59.705202183Z","tags":null},"/about-the-website":{"title":"how to make this website","content":"","lastmodified":"2022-12-07T10:54:59.705202183Z","tags":null},"/concept/Cantors-diagonal-argument":{"title":"Cantor's diagonal argument","content":"\nOne of Cantor's theorem is that the set of all sets of natural numbers is not enumerable. \nThe set of real numbers is the set of all set of natural numbers because you form a real number by precising its decimals. It is therefore not an [[definition/enumerable set]].\n\n#### Proof: \nWe consider the set of all sets of natural numbers $SS=\\{S_1,S_2,...\\}$ and there characteristic functions $s_1,s_2, ...$ . $s_n(m)=1 \\ if \\  m\\in S_n$  and $0$ if not. We can construct a matrix with $M_{nm}=s_n(m)$. We want to show that there is a set that is not in $SS$. \n\nConsider the *antidiagonal* sequence  $\\{1-s_n(n)\\}_n$. If this set is already in $SS$ it means that $\\exists n , \\forall m , s_n(m)=1-s_m(m)$ . For $m=n$  it would mean that $s_n(n)=1-s_n(n)$. Such $n$  does not exist and therefore, this set is missing from $SS$: is does not contain all sets of natural numbers.\n \n\n#### Sources \n\n[Boolos et al, 2007](reference/Boolos%20et%20al,%202007.md)\n\n","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/concept/Church-Turing-thesis":{"title":"Church-Turing thesis","content":"\n*An [[definition/arithmetic function]] is [[definition/effectively computable]] if and only if it is computable by a [[concept/Turing machine]] (or — using the [[definition/computable]] equivalence — if it is is a [[definition/recursive function]])*.\n\nThis is a thesis because it is not provable because it refers to the informal [[definition/effectively computable]] notion. We know for sure one way (the return) because a Turing machine is computation is a type of effective computation.\n\n*Why believe it?* \nAll attempts to give an exact analysis of the intuitive notion of an effectively calculable function have turned out to be _equivalent_, in the sense that each analysis offered has been proved to pick out the same class of functions, namely those that are computable by Turing machine.\nChurch has made such an hypothesis independently with other sort of computation (abacus machine).\n\n#### Sources \n[Standford Encyclopedia](https://plato.stanford.edu/entries/church-turing/#MisuThes)\n[Wikipedia](https://en.wikipedia.org/wiki/Church%E2%80%93Turing_thesis)\n\n","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/concept/Shannons-theory-of-information-transmission":{"title":"Shannon's theory of information transmission","content":"\nBe $X$  a random variable with $X\\in\\{x_1,x_2,...,x_n\\}$ and $p_i=\\mathbb{P}(X=x_i)$. Shannon relates the amount of information of one string to the amount of surprise of seeing it. The information is defined as $$I(X) = - \\log(P(X))$$and the expected value gives the amount of  \"**information, choice or uncertainty**\" — [Shannon, 1948](reference/Shannon,%201948.md) as follows  $$H(X)=E(I(X))=-\\sum_i p_i \\log(p_i)$$This formula happens to be the same as the one for Gibbs [[entropy]] (with an additional Boltzmann constant) in the framework of [[second principe de la thermodynamique]]. Therefore, Shannon makes the link between information and positive entropy (as pointed out by [[Brillouin's relation between entropy and information]]). This is peculiar because as entropy (and disorder) increases, information is lost. It is now preferred to give the name **entropy** to $H(X)$.  We use the meaning of **uncertainty** in this case. \n\n#### Exemple(s)\nA series of fair coin tosses have a maximal entropy $H$ since all throw are equiprobable (maximal uncertainty). \n\n#### Sources \n[Shannon, 1948](reference/Shannon,%201948.md)\n[[Longo_et_al_information_observable_2012]]","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/concept/Turing-machine":{"title":"Turing machine","content":"\nIn 1936, Turing introduces the idea of “computing machine”, latter called “Turing machine”. He pictures not a mecanism but a person — “Turing's architect” according to ([Schrödinger, 1944](reference/Schrödinger,%201944.md)). Turing introduced ([Turing, 1936](reference/Turing,%201936.md)) this machine trying to answer questions regarding decidability. A Turing machine is an [automaton](definition/automaton.md) with an unlimited and unrestricted memory. It is a model of everything that can do today's computers. It requires a (readable, writtable, and movable) infinite 1D bit register — a tape. Turing has shown that those elementary instructions are enough to do elaborate any sophisticated program that are themselves encoded on the tape. The Turing machine allocates a data space to make the computation and another one where the programs are encoded. The operating system read the instructions as it computes the program and change the input binary string. Increasing the complexity of the machine (e.g. alphabet, dimensions) does not change the class of functions it can computes ([recursive function](definition/recursive%20function.md)s). \n\n\n#### Details \n\n**What is the formal definition of a Turing machine ?** \nThe alphabet of the tape $\\Gamma$ can be thought to be 0's and 1's and blank's. \n\n$$\\begin{array}{l}\\text { A Turing machine is a 7-tuple, }\\left(Q, \\Sigma, \\Gamma, \\delta, q_{0}, q_{\\text {accept }}, q_{\\text {reject }}\\right) \\text {, where } \\\\ Q, \\Sigma, \\Gamma \\text { are all finite sets and } \\\\ \\text { 1. } Q \\text { is the set of states, } \\\\ \\text { 2. } \\Sigma \\text { is the input alphabet not containing the blank symbol } \\sqcup \\text {, } \\\\ \\text { 3. } \\Gamma \\text { is the tape alphabet, where } \\sqcup \\in \\Gamma \\text { and } \\Sigma \\subseteq \\Gamma \\text {, } \\\\ \\text { 4. } \\delta: Q \\times \\Gamma \\longrightarrow Q \\times \\Gamma \\times\\{\\mathrm{L}, \\mathrm{R}\\} \\text { is the transition function, } \\\\ \\text { 5. } q_{0} \\in Q \\text { is the start state, } \\\\ \\text { 6. } q_{\\text {accept }} \\in Q \\text { is the accept state, and } \\\\ \\text { 7. } q_{\\text {reject }} \\in Q \\text { is the reject state, where } q_{\\text {reject }} \\neq q_{\\text {accept }}\\end{array}$$\n\n**How to write the program (or diagram or table of instructions) in the machine ?**\n\nWe write $S_0=blank$ , $S_1=0$ and $S_2=1$, $R=move \\ right$, $L= move \\ left$ . \nAn instruction can be written $q_i S_i S_j R q_m$  or  $q_i S_i S_j L q_m$. We encode all instructions that define the Turing machine, as follows $$q_1 S_0 S_0 L q_2 ; q_2 S_1 S_2 L q_3 ; ... $$We write $q_i=DAAAA...A$ ($i$  times), $S_i=DCCC...C$ ($i$  times) and give a integer to each letter (A=1, C=2, D=3,...,;=7). Therefore, it gives a description number for the Turing machine $$313325117 ...$$There is a unique integer for a given machine, but we can always add unecessary programs (that change the number but that give the same result). This integer gets a binary decomposition$$01000101011010$$With the help of an additional small and instantaneous \"workspace\", it uses a [simple mecanism](https://www.youtube.com/watch?v=P66h8D5Lkwk) to read the programs and compute at the same time.\n\n\n\n#### Exemple(s) \n\n\n\n#### Sources :\n[Stanford Encyclopedia of Philosophy](https://plato.stanford.edu/entries/turing-machine/#TuriDefi)\n[MIT Open courses](https://ocw.mit.edu/courses/18-404j-theory-of-computation-fall-2020/pages/syllabus/)\n[Sipser, 2013](reference/Sipser,%202013.md)\nnote [on Longo et al, 2012](note/on%20Longo%20et%20al,%202012.md)\n[Youtube](https://www.youtube.com/watch?v=P66h8D5Lkwk) \n[Wikipedia](https://en.wikipedia.org/wiki/Turing_machine)\n[Turing, 1936](reference/Turing,%201936.md)","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/concept/halting-problem":{"title":"halting problem","content":"\nGiven a [[concept/Turing machine]] and an initial binary strings, the problem consists in knowing if it will halt or not. This problem cannot be solve on a [[concept/Turing machine]] because the halting function is [[definition/uncomputable]]. \n","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/definition/abacus":{"title":"abacus","content":"\nAn abacus is a \"higher-level\" (more flexible) [[concept/Turing machine]] for computation.\nEvery abacus-computable function is Turing computable. \nAll [[definition/recursive function]]s are abacus-computable. \n\n#### Source(s)\n\n[Boolos et al, 2007](reference/Boolos%20et%20al,%202007.md)","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/definition/arithmetic-function":{"title":"arithmetic function","content":"\nA function whose domain is $\\mathbb{N}$.","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/definition/automaton":{"title":"automaton","content":"\nFormally, a finite automaton can be defined as \n$$\\begin{array}{l}\\text { A finite automaton (or machine) is a } 5 \\text {-tuple } M=\\left(Q, \\Sigma, \\delta, q_{0}, F\\right) \\text {, where } \\\\ \\text { 1. } Q \\text { is a finite set called the states, } \\\\ \\text { 2. } \\Sigma \\text { is a finite set called the alphabet, } \\\\ \\text { 3. } \\delta: Q \\times \\Sigma \\longrightarrow Q \\text { is the transition function, } \\\\ \\text { 4. } q_{0} \\in Q \\text { is the start state, and } \\\\ \\text { 5. } F \\subseteq Q \\text { is the set of accept states. }{ }\\end{array}$$\nIt takes as input an binary *string* to gives the states $q_i$ . Some input strings are accepted (because you reach the final state or \"accepted state\"), some are rejected. All the input strings form the *language* of the machine $L(M)$. \n\n#### Exemple(s) \n\nThe final state is $q_2$  here. The alphabet $\\Sigma=\\{0,1\\}$ .\n\n\n#### Sources \n\n[Sipser, 2013](reference/Sipser,%202013.md)\n[MIT Open courses](https://ocw.mit.edu/courses/18-404j-theory-of-computation-fall-2020/pages/syllabus/)","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/definition/computable":{"title":"computable","content":"\nThree notions of computability are equivalent: \n- The existence of a [[concept/Turing machine]] computing the function.\n- The [[definition/abacus]]-computability.\n- A [[definition/recursive function]]. \nA function is computable on a [[concept/Turing machine]] if and only if it is a [[definition/recursive function]].\n\n[[concept/Church-Turing thesis]] assumes that it is the same thing as [[definition/effectively computable]]. \nSome functions are however [[definition/uncomputable]]. \n\n#### Exemple(s) \n\n#### Sources \n\n[Boolos et al, 2007](reference/Boolos%20et%20al,%202007.md)","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/definition/effectively-computable":{"title":"effectively computable","content":"\nThis *informal notion* also refers to: \n- procedure \n- paper-and-pencil method or \n- to a mechanical method \n\nIt is specific to a type of problem but we can state:\n\n- A finite number of instructions.\n- It always terminates after a finite number of steps.\n- It always produces a correct answer.\n- It can be done by a human without any aids except writing materials.\n- Its instructions need only to be followed rigorously to succeed : it requires no ingenuity\n\n#### Source(s)\n\n[Wikipedia](https://en.wikipedia.org/wiki/Effective_method)\n","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/definition/entropy":{"title":"entropy","content":"\nFor a given phase space and Hamiltonian, entropies quantifies the number of micro-states available, for a given energy.\n\n#### Details \n\nIn the Gibbs (canonical) ensemble (NVT), the partition function reads $$ Z = \\sum_i e^{-\\beta E_i} $$an with the probability of the micro-state $i$  being  $p_i=e^{-\\beta E_i} / Z$, we have \n$$ S_G=-k_B \\sum_i p_i \\log(p_i) $$\n\nFor a fixed energy, in the micro-canonical ensemble (NVE), the energy is fixed and we get $$ \\Omega = \\sum_i 1 $$ and Boltzmann's entropy  $$ S_B = k_B \\log(\\Omega )$$They are equal by restricting the sum for a given energy $E$ in the summation of the (NVT) ensemble. It gives $Z=e^{-\\beta E}\\Omega$ and $S_G = S_B$.\n","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/definition/enumerable-set":{"title":"enumerable set","content":"\nA set is enumerable if and only if it is the range of some [[definition/arithmetic function]].\n\n(The range is the set of the function's values.\nThe domain is the set of the functions's argument.)\n\n#### Source(s)\n\n[Boolos et al, 2007](reference/Boolos%20et%20al,%202007.md)","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/definition/recursive-function":{"title":"recursive function","content":"\nIt refers to functions that can be built with the zero, the successor and the identity function by use of composition, minimization and primitive recursion: $$h(x,0)=f(x), \\ h(x,y')=g(x,y,h(x,y))$$\nThey are all [[definition/effectively computable]].\n\n#### Exemple(s) \n\n#### Sources \n\n[Boolos et al, 2007](reference/Boolos%20et%20al,%202007.md)\n","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/definition/uncomputable":{"title":"uncomputable","content":"\nDue to [Cantor's diagonal argument](concept/Cantor's%20diagonal%20argument.md), we know that the set of [[arithmetic function]]s that have a range on positive integers is not an [[enumerable set]]. But the set of [[Turing machine]]s is an [[enumerable set]] because they can be expressed as quadruplets. There are functions are not computable by a [[Turing machine]]. Assuming [[Church-Turing thesis]], they are functions that are not [[effectively computable]]. For instance, solving the [[halting problem]] requires the introduction of the halting function (that takes as argument a Turing machine and a binary string) that is not Turing-computable. \n\n","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/manifesto":{"title":"manifesto","content":"\n","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/note/on-Longo-et-al-2012":{"title":"on Longo et al, 2012","content":"\n\n**Is Information a proper observable for biological organization?**    \nby Longo G., Miquel P., Sonnenschein C., Soto A.M.     \n2012\n\nReference: [Longo et al, 2012](reference/Longo%20et%20al,%202012.md)\n\n**DNA was discovered in times that proned an informational metaphor for biological organization**. The discovery of DNA by Crick and Watson in 1953 happened just after an flourishing era of mathematical logic and computation. The concepts of (hardware and software-independent) [computable](definition/computable.md), elaboration of information (reading and programming) with [Turing machine](concept/Turing%20machine.md)s were developped in 1930-1936. At the end of WW2 (were cryptography played a major role), [[Schrödinger's code-script aperiodic crystal]] hints at informational encoding in chromosomes, such as *programs*. In 1948, [[Shannon's theory of information transmission]], which is still crucial nowadays also poped up. The informational metaphor for biological organization (without the hypothesis of the abstract model of mathematical logic) laid out the groundwork for a simplistic explanation of [[Mendel's laws of inheritance]] with the four bases discovered in the DNA. This metaphor is at the core of [[Crick's central dogma]]. \n\n\n\n\n\n","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/reference/Boolos-et-al-2007":{"title":"Boolos et al, 2007","content":"\n","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/reference/Longo-et-al-2012":{"title":"Longo et al, 2012","content":"- Longo G., Miquel P., Sonnenschein C., Soto A.M. (2012). \"Is Information a proper observable for biological organization?.\" *Progress in biophysics and molecular biology* 109: 108-114. doi: 10.1016/j.pbiomolbio.2012.06.004\n\n\u003e [!quote] \n\u003e\n\u003e*“So, the “constraints” or the interactions in living organisms, given by either the cells, the different levels of organization and/or by the ecosystems cannot causally and positively contribute to the generation and maintenance of the organism unless they are digitally encoded as molecular signs.”* —  (p. 6) \n\n\n","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/reference/Schr%C3%B6dinger-1944":{"title":"Schrödinger, 1944","content":"\n**What is Life?: With Mind and Matter and Autobiographical Sketches**     \nby Schrödinger E. in **1944**.\n\n","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/reference/Shannon-1948":{"title":"Shannon, 1948","content":"- A mathematical theory of communication\n- Shannon C.E. \n- 1948\n\n\n","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/reference/Sipser-2013":{"title":"Sipser, 2013","content":"\n","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null},"/reference/Turing-1936":{"title":"Turing, 1936","content":"\n","lastmodified":"2022-12-07T10:54:59.709202231Z","tags":null}}